{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project: Traffic signs recognition and\n",
    "\n",
    "We'll check out how to build a **convolutional network** to classify CIFAR10 images. By using weight sharing - multiple units with the same weights - convolutional layers are able to learn repeated patterns in your data. For example, a unit could learn the pattern for an eye, or a face, or lower level features like edges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as utils\n",
    "from readTrafficSigns import readTrafficSigns\n",
    "import random\n",
    "import math\n",
    "import scipy.misc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_TrafficSigns():\n",
    "    \"\"\"\n",
    "    Load the German Traffic Sign Recognition Benchmark dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier.  \n",
    "    \"\"\"\n",
    "    # Load the raw traffic signs data\n",
    "    trafficSigns_dir = './data/train/Final_Training/Images'\n",
    "    X_train, y_train = readTrafficSigns(trafficSigns_dir)\n",
    "    \n",
    "    \n",
    "    #print (len(X_train))   #vector of dimension 39209 --> one element per image : for each image (element) we get a matrix for each pixel containing the RGBs\n",
    "    #print (len(y_train))   #vector of dimension 39209 --> one element per image : for each image (element) we get the number of the class it belongs to \n",
    "    #print (y_train[0])\n",
    "    #print (type(y_train))\n",
    "     #for the moment, images are classed in order --> firt 210 images belong to class 0 (y=0), next ones belong to class 1 etc...\n",
    "\n",
    "    ind = list()\n",
    "    \n",
    "    # subsample the data\n",
    "    for i in range(0,43):\n",
    "        \n",
    "        index_value = list()\n",
    "        for j in range (0,39209):\n",
    "            if int(y_train[j]) == i:\n",
    "                index_value.append(j)\n",
    "        ind.append(random.sample(range(min(index_value),max(index_value)+1), math.floor(0.02*len(index_value))))\n",
    "    \n",
    "    ind2 = [item for sublist in ind for item in sublist]\n",
    "    X_val = [X_train[i] for i in ind2]\n",
    "    y_val = [y_train[i] for i in ind2]\n",
    "    for ind2 in sorted(ind2, reverse=True):\n",
    "        del X_train[ind2]\n",
    "        del y_train[ind2]\n",
    "   \n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val = get_data_TrafficSigns()\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-77fb7391a9cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m48\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mX_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-77fb7391a9cb>\u001b[0m in \u001b[0;36mresize\u001b[0;34m(X, length, width)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtransp_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransp_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mX_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def resize(X, length, width):\n",
    "    X_new = np.empty(shape=(0,3,length,width))\n",
    "    for i in range(len(X)):\n",
    "        image = X[i];\n",
    "        image = scipy.misc.imresize(image, (length, width, 3))\n",
    "        transp_image = image.transpose(2,0,1)\n",
    "        y = np.expand_dims(transp_image, axis=0)\n",
    "        X_new = np.concatenate((X_new,y), axis=0)\n",
    "\n",
    "    return X_new  \n",
    "\n",
    "n = 47\n",
    "X_train = resize(X_train, n,n)\n",
    "X_val = resize(X_val, n,n)\n",
    "y_train = np.asarray(y_train)\n",
    "y_val = np.asarray(y_val)\n",
    "\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "\n",
    "X_train, y_train = torch.from_numpy(X_train).type(torch.FloatTensor), torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "X_val, y_val = torch.from_numpy(X_val).type(torch.FloatTensor), torch.from_numpy(y_val).type(torch.LongTensor)\n",
    "\n",
    "traindataset = utils.TensorDataset(X_train, y_train)\n",
    "trainloader = utils.DataLoader(traindataset, batch_size=64, shuffle=True)\n",
    "\n",
    "valdataset = utils.TensorDataset(X_val, y_val)\n",
    "valloader = utils.DataLoader(valdataset, batch_size=64, shuffle=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, n_input_channels=3, n_output=43):\n",
    "        super().__init__()\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Define 2 or more different layers of the neural network                      #\n",
    "        ################################################################################\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(n_input_channels, 70, 5, stride = 1, padding = 2)\n",
    "        self.pool = nn.MaxPool2d(3, stride=2)\n",
    "        self.conv2 = nn.Conv2d(70, 110, 3, stride = 1, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(110,180,3, stride=1, padding = 1)\n",
    "        self.fc1 = nn.Linear(180 * 5 * 5, 200)\n",
    "        self.fc2 = nn.Linear(200, 100)\n",
    "        self.fc3 = nn.Linear(100, n_output)\n",
    "        \n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Set up the forward pass that the input data will go through.                 #\n",
    "        # A good activation function betweent the layers is a ReLu function.           #\n",
    "        #                                                                              #\n",
    "        # Note that the output of the last convolution layer should be flattened       #\n",
    "        # before being inputted to the fully connected layer. We can flatten           #\n",
    "        # Variable `x` with `x.view`.                                                  #\n",
    "        ################################################################################  \n",
    "        \n",
    "        x = F.relu(self.pool(self.conv1(x)))\n",
    "        x = F.relu(self.pool(self.conv2(x)))\n",
    "        x = F.relu(self.pool(self.conv3(x)))\n",
    "        x = x.view(-1, 180 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def predict(self, x):\n",
    "        logits = self.forward(x)\n",
    "        return F.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ConvNet()\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Choose an Optimizer that will be used to minimize the loss function.         #\n",
    "# Choose a critera that measures the loss                                      #\n",
    "################################################################################\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.005)\n",
    "\n",
    "epochs = 3\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 30\n",
    "for e in range(epochs):\n",
    "    start = time.time()\n",
    "    for images, labels in iter(trainloader):\n",
    "        \n",
    "        steps += 1\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Run the training process                                                     #\n",
    "        #                                                                              #\n",
    "        # HINT: Do not forget to transform the inputs and outputs into Variable        #\n",
    "        # which pytorch uses.                                                          #\n",
    "        ################################################################################\n",
    "        \n",
    "        #transofrm inputs and outputs into Variable \n",
    "        inputs, targets = Variable(images), Variable(labels)\n",
    "        \n",
    "        #set gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        out = net.forward(inputs)\n",
    "        \n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "        \n",
    "        loss = criterion(out, targets)\n",
    "        \n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Run the training process                                                     #\n",
    "        #                                                                              #\n",
    "        # HINT: Calculate the gradient and move one step further                       #\n",
    "        ################################################################################\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "        \n",
    "        running_loss += loss.data[0]\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            stop = time.time()\n",
    "            # Test accuracy\n",
    "            accuracy = 0\n",
    "            for ii, (images, labels) in enumerate(valloader):\n",
    "                \n",
    "                ################################################################################\n",
    "                # TODO:                                                                        #\n",
    "                # Calculate the accuracy                                                       #\n",
    "                ################################################################################\n",
    "                \n",
    "                out = net.predict(Variable(images))\n",
    "                _, prediction = torch.max(out, 1)\n",
    "                pred_y = prediction.data.numpy().squeeze()\n",
    "                target_y = (labels.numpy()).data\n",
    "                accuracy += sum(pred_y == target_y)/64\n",
    "                \n",
    "                ################################################################################\n",
    "                #                              END OF YOUR CODE                                #\n",
    "                ################################################################################\n",
    "            \n",
    "            print(\"Epoch: {}/{}..\".format(e+1, epochs),\n",
    "                  \"Loss: {:.4f}..\".format(running_loss/print_every),\n",
    "                  \"Test accuracy: {:.4f}..\".format(accuracy/(ii+1)),\n",
    "                  \"{:.4f} s/batch\".format((stop - start)/print_every)\n",
    "                 )\n",
    "            running_loss = 0\n",
    "            start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'project.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
